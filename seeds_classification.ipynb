{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Variedades de Grãos de Trigo (Seeds Dataset)\n",
    "\n",
    "## Metodologia CRISP-DM\n",
    "\n",
    "Este projeto segue a metodologia CRISP-DM (Cross-Industry Standard Process for Data Mining) para desenvolver um modelo de aprendizado de máquina capaz de classificar variedades de grãos de trigo com base em suas características físicas, utilizando o **Seeds Dataset** do UCI Machine Learning Repository.\n",
    "\n",
    "### 1. Entendimento do Negócio\n",
    "\n",
    "**Problema:** Em cooperativas agrícolas de pequeno porte, a classificação dos grãos é realizada manualmente por especialistas, o que é demorado e sujeito a erros. A automação desse processo pode aumentar a eficiência e a precisão.\n",
    "\n",
    "**Objetivo:** Desenvolver um modelo de classificação de aprendizado de máquina para distinguir três variedades de grãos de trigo (Kama, Rosa e Canadian) com base em 7 características geométricas.\n",
    "\n",
    "### 2. Entendimento dos Dados\n",
    "\n",
    "O conjunto de dados contém 210 amostras de grãos de trigo, 70 de cada variedade. As características (atributos) são:\n",
    "\n",
    "1.  **Area** (Área)\n",
    "2.  **Perimeter** (Perímetro)\n",
    "3.  **Compactness** (Compacidade)\n",
    "4.  **Length of kernel** (Comprimento do Núcleo)\n",
    "5.  **Width of kernel** (Largura do Núcleo)\n",
    "6.  **Asymmetry coefficient** (Coeficiente de Assimetria)\n",
    "7.  **Length of kernel groove** (Comprimento do Sulco do Núcleo)\n",
    "8.  **Target** (Variedade do Grão: 1=Kama, 2=Rosa, 3=Canadian)\n",
    "\n",
    "### 3. Preparação dos Dados (Análise Exploratória e Pré-processamento)\n",
    "\n",
    "#### 3.1. Carregamento e Inspeção Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuração para visualização\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Carregar o dataset a partir do arquivo TXT baixado\n",
    "# O arquivo TXT não tem cabeçalho e os dados são separados por espaços.\n",
    "# As colunas são: Area, Perimeter, Compactness, Length of kernel, Width of kernel, Asymmetry coefficient, Length of kernel groove, Variety (target)\n",
    "column_names = ['Area', 'Perimeter', 'Compactness', 'Length_of_kernel', 'Width_of_kernel', 'Asymmetry_coefficient', 'Length_of_kernel_groove', 'Variety']\n",
    "df = pd.read_csv('seeds_dataset.txt', sep='\\s+', header=None, names=column_names, skipinitialspace=True)\n",
    "\n",
    "# Mapear os valores numéricos para os nomes das variedades\n",
    "variety_map = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}\n",
    "df['Variety_Name'] = df['Variety'].map(variety_map)\n",
    "\n",
    "# Exibir as primeiras linhas\n",
    "print('Primeiras 5 linhas do Dataset:')\n",
    "print(df.head())\n",
    "\n",
    "# Informações gerais sobre o dataset\n",
    "print('\\nInformações do Dataset:')\n",
    "df.info()\n",
    "\n",
    "# Verificar a contagem de classes\n",
    "print('\\nContagem de Variedades:')\n",
    "print(df['Variety_Name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Estatísticas Descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estatísticas descritivas\n",
    "print('Estatísticas Descritivas:')\n",
    "print(df.drop(columns=['Variety', 'Variety_Name']).describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Visualização da Distribuição das Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma para todas as features\n",
    "df.drop(columns=['Variety', 'Variety_Name']).hist(bins=15, figsize=(15, 10), layout=(3, 3))\n",
    "plt.suptitle('Distribuição das Características (Histogramas)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para todas as features, agrupados por variedade\n",
    "features = df.drop(columns=['Variety', 'Variety_Name']).columns\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x='Variety_Name', y=feature, data=df)\n",
    "    plt.title(f'Boxplot de {feature} por Variedade')\n",
    "    plt.xlabel('Variedade')\n",
    "    plt.ylabel(feature)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Análise de Correlação e Relações entre Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação\n",
    "correlation_matrix = df.drop(columns=['Variety', 'Variety_Name']).corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de Correlação entre as Características')\n",
    "plt.show()\n",
    "\n",
    "# Gráficos de Dispersão (Pair Plot) para identificar relações\n",
    "sns.pairplot(df.drop(columns=['Variety']), hue='Variety_Name', palette='viridis')\n",
    "plt.suptitle('Gráficos de Dispersão das Características por Variedade', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Tratamento de Valores Ausentes e Verificação de Tipos de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de valores ausentes\n",
    "print('Valores Ausentes por Coluna:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Verificação de tipos de dados (já feita com df.info(), mas repetindo para clareza)\n",
    "print('\\nTipos de Dados:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6. Padronização/Normalização das Características\n",
    "\n",
    "Modelos baseados em distância (como KNN e SVM) são sensíveis à escala das features. A análise exploratória (Estatísticas Descritivas e Boxplots) mostrará que as features têm escalas diferentes. Portanto, a padronização (StandardScaler) ou normalização (MinMaxScaler) será necessária. A padronização é geralmente preferida para algoritmos que assumem distribuição normal, mas o MinMaxScaler pode ser útil para preservar a forma da distribuição. Para este projeto, utilizaremos a **Padronização (StandardScaler)**, que transforma os dados para ter média 0 e desvio padrão 1, o que é um bom ponto de partida para a maioria dos algoritmos de ML.\n",
    "\n",
    "**Nota:** A padronização será aplicada após a separação dos dados em treino e teste (na próxima fase) para evitar *data leakage*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelagem (Implementação e Comparação de Algoritmos)\n",
    "\n",
    "#### 4.1. Separação dos Dados e Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separar features (X) e target (y)\n",
    "X = df.drop(columns=['Variety', 'Variety_Name'])\n",
    "y = df['Variety']\n",
    "\n",
    "# Separar em conjuntos de treinamento e teste (70% treino, 30% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Padronizar as features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Dados separados e padronizados com sucesso.')\n",
    "print(f'Shape de X_train_scaled: {X_train_scaled.shape}')\n",
    "print(f'Shape de X_test_scaled: {X_test_scaled.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Implementação e Avaliação dos Modelos Base\n",
    "\n",
    "Serão implementados e comparados os seguintes algoritmos de classificação:\n",
    "\n",
    "1.  **K-Nearest Neighbors (KNN)**\n",
    "2.  **Support Vector Machine (SVM)**\n",
    "3.  **Random Forest**\n",
    "4.  **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=200)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print('Treinando e avaliando modelos base...')\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Treinamento\n",
    "    if name in ['KNN', 'SVM']:\n",
    "        # Modelos baseados em distância usam dados escalados\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        # Modelos de árvore e regressão logística podem usar dados não escalados, mas usaremos escalados para consistência\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "    # Avaliação\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "        'Classification Report': classification_report(y_test, y_pred, target_names=variety_map.values(), output_dict=True)\n",
    "    }\n",
    "    \n",
    "    print(f'\\nModelo {name} treinado e avaliado.')\n",
    "    print(f'Acurácia: {accuracy:.4f}')\n",
    "    \n",
    "# Comparação dos resultados\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'Accuracy': [res['Accuracy'] for res in results.values()],\n",
    "    'Precision (Macro)': [res['Precision'] for res in results.values()],\n",
    "    'Recall (Macro)': [res['Recall'] for res in results.values()],\n",
    "    'F1-Score (Macro)': [res['F1-Score'] for res in results.values()]\n",
    "})\n",
    "\n",
    "print('\\nComparação de Desempenho dos Modelos Base:')\n",
    "print(comparison_df.sort_values(by='F1-Score (Macro)', ascending=False).reset_index(drop=True))\n",
    "\n",
    "# Visualização das Matrizes de Confusão\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    sns.heatmap(res['Confusion Matrix'], annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[i],\n",
    "                xticklabels=variety_map.values(), yticklabels=variety_map.values())\n",
    "    axes[i].set_title(f'Matriz de Confusão - {name}')\n",
    "    axes[i].set_xlabel('Predito')\n",
    "    axes[i].set_ylabel('Verdadeiro')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Avaliação (Otimização dos Modelos)\n",
    "\n",
    "Com base nos resultados da comparação, o modelo com melhor desempenho será selecionado para otimização de hiperparâmetros usando `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Selecionar o melhor modelo (assumindo que o SVM ou Random Forest será o melhor)\n",
    "# Vamos otimizar o SVM, que geralmente se beneficia da padronização e é um bom candidato para este dataset.\n",
    "best_model_name = 'SVM'\n",
    "best_model = SVC(random_state=42)\n",
    "\n",
    "# Definir o grid de hiperparâmetros para o SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "print(f'Iniciando otimização de hiperparâmetros para o modelo {best_model_name}...')\n",
    "\n",
    "grid_search = GridSearchCV(best_model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Melhores hiperparâmetros encontrados:')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo otimizado\n",
    "optimized_model = grid_search.best_estimator_\n",
    "y_pred_optimized = optimized_model.predict(X_test_scaled)\n",
    "\n",
    "# Avaliar o modelo otimizado\n",
    "accuracy_opt = accuracy_score(y_test, y_pred_optimized)\n",
    "f1_opt = f1_score(y_test, y_pred_optimized, average='macro')\n",
    "conf_matrix_opt = confusion_matrix(y_test, y_pred_optimized)\n",
    "class_report_opt = classification_report(y_test, y_pred_optimized, target_names=variety_map.values())\n",
    "\n",
    "print(f'\\nDesempenho do Modelo Otimizado ({best_model_name}):')\n",
    "print(f'Acurácia: {accuracy_opt:.4f}')\n",
    "print(f'F1-Score (Macro): {f1_opt:.4f}')\n",
    "print('\\nRelatório de Classificação:\\n', class_report_opt)\n",
    "\n",
    "# Visualização da Matriz de Confusão Otimizada\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_opt, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=variety_map.values(), yticklabels=variety_map.values())\n",
    "plt.title(f'Matriz de Confusão - {best_model_name} Otimizado')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Implantação (Interpretação e Insights)\n",
    "\n",
    "#### 6.1. Interpretação dos Resultados\n",
    "\n",
    "A análise final será realizada com base nos resultados obtidos, focando em:\n",
    "\n",
    "1.  **Comparação Pré e Pós-Otimização:** Houve melhoria significativa no desempenho após a otimização de hiperparâmetros?\n",
    "2.  **Análise da Matriz de Confusão:** Quais variedades são mais difíceis de classificar (mais erros de confusão)?\n",
    "3.  **Importância das Features (para Random Forest):** Quais características geométricas são mais relevantes para a classificação?\n",
    "\n",
    "#### 6.2. Importância das Features (para o Random Forest Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-treinar o Random Forest (modelo base) para extrair a importância das features\n",
    "rf_model = models['RandomForest']\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances.values, y=feature_importances.index, palette='viridis')\n",
    "plt.title('Importância das Features (Random Forest)')\n",
    "plt.xlabel('Score de Importância')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "print('Importância das Features:\\n', feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
